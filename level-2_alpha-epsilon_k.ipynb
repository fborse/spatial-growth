{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e13c800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "266dfcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8af82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea755b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from commons import smoothen, lse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "157a8f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b1bdc7",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d7f2bd",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa81fddf",
   "metadata": {},
   "source": [
    "We start by loading the $N_i(t)$, while smoothening them :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73e0c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nt = np.moveaxis(np.load(\"synthetic-data.npy\"), 1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893592bf",
   "metadata": {},
   "source": [
    "Let's also calculate already the derivatives $\\frac{\\Delta N_i(t)}{\\Delta t} = \\Delta N_i(t) = N_i(t+1) - N_i(t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb0c76e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dNdt = Nt[..., 1:] - Nt[..., :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12169a02",
   "metadata": {},
   "source": [
    "and $\\rho_i(t) = \\frac{\\Delta N_i(t)}{N_i(t)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95b90625",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = dNdt / Nt[..., :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971fa458",
   "metadata": {},
   "source": [
    "Let's get the number of points consistent between $N_i(t)$ and the derivatives :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1edcb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nt = Nt[..., :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7739c370",
   "metadata": {},
   "source": [
    "## Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a291b27",
   "metadata": {},
   "source": [
    "We also get the dimensions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4f00cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plates, n_rows, n_columns, n_points = Nt.shape\n",
    "plates, rows, columns, points = map(np.arange, Nt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4999cdb6",
   "metadata": {},
   "source": [
    "## Initial $\\alpha_i(t)$ parameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38adaf44",
   "metadata": {},
   "source": [
    "The population-and-location-specific $\\rho_i(t) = \\alpha_i(t) \\; \\epsilon_k(t)$ model requires us to provide $\\alpha_i(t)$ values, which we load here.\n",
    "To get the time dimensionality consistent with the $\\rho_i(t)$, we remove its last time point :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31dd5582",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.load(\"alpha/computed.npy\")[..., :-11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2cabf1",
   "metadata": {},
   "source": [
    "As we will recompute these values iteratively, along with the parameters that lead for those values, so here are some initial parameter values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "470369b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = pd.read_csv(\"alpha/params.csv\")\n",
    "alphas.index = pd.MultiIndex.from_frame(alphas[[\"plate\", \"row\", \"column\"]])\n",
    "alphas = alphas[[\"r0 i\", \"c i\", \"m i\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56dc945",
   "metadata": {},
   "source": [
    "The $r_0$ and $m$ parameters are global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "261102e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r0_m = pd.DataFrame(index = pd.Index(plates, name = \"plate\"))\n",
    "\n",
    "r0_m[\"r0\"] = alphas[\"r0 i\"].unique()\n",
    "r0_m[\"m\"] = alphas[\"m i\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d3d083",
   "metadata": {},
   "source": [
    "while the $c_i$ parameters are population-specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5d67cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_i = alphas[\"c i\"]\n",
    "c_i.index = alphas.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5ccffe",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e57ed0d",
   "metadata": {},
   "source": [
    "The $\\epsilon_k(t)$ are organised in $k = 16$ layers, defined as equidistant points compared to their closest grid border.\n",
    "We create here 16 matrices where for each layer the respective coordinates in the grid are set to 1 (0 otherwise) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9a8a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = np.zeros((16, n_rows, n_columns))\n",
    "\n",
    "for i in range(16):\n",
    "    layers[i, i, i:n_columns-i] = 1\n",
    "    layers[i, i:n_rows-i, i] = 1\n",
    "    layers[i, n_rows-i-1, i:n_columns-i] = 1\n",
    "    layers[i, i:n_rows-i, n_columns-i-1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22c33d6",
   "metadata": {},
   "source": [
    "Convert a coordinate to the corresponding $\\epsilon_k$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc0d5b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2l = sum( (i+1) * l for i, l in enumerate(layers) ).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43280fe",
   "metadata": {},
   "source": [
    "# $\\hat\\rho_i(t) = \\alpha_i(t) \\; \\epsilon_k(t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da9e3d",
   "metadata": {},
   "source": [
    "The general idea with this model is that we find a value for $\\epsilon_k(t)$ for every time point $t$ and layer $k$.\n",
    "Then, if we recompute new optimal parameters for $\\alpha_i(t)$, and then for $\\epsilon_k(t)$ again, we obtain an iterative process :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbc110c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = pd.DataFrame(\n",
    "    data    = np.empty((n_plates * n_points, 16)),\n",
    "    columns = [ f\"epsilon {k+1}\" for k in range(16) ],\n",
    "    index   = pd.MultiIndex.from_product((plates, points), names = (\"plate\", \"time point\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "838d63e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_new_epsilons():\n",
    "    global previous_epsilon\n",
    "    previous_epsilon = epsilon.copy()\n",
    "    \n",
    "    for p in plates:\n",
    "        t = 0\n",
    "        epsilon.loc[p, t] = curve_fit(\n",
    "            f     = lambda _, e1, e2, e3, e4, e5, e6, e7, e8, e9, e10, e11, e12, e13, e14, e15, e16:\n",
    "                        alpha[p, ..., t].reshape(-1) * np.array([e1, e2, e3, e4, e5, e6, e7, e8, e9, e10, e11, e12, e13, e14, e15, e16]).dot(layers.reshape((16, -1))),\n",
    "            xdata = t,\n",
    "            ydata = rho[p, ..., t].reshape(-1)\n",
    "        )[0]\n",
    "\n",
    "        for t in points[1:]:\n",
    "            epsilon.loc[p, t] = curve_fit(\n",
    "                f     = lambda _, e1, e2, e3, e4, e5, e6, e7, e8, e9, e10, e11, e12, e13, e14, e15, e16:\n",
    "                            alpha[p, ..., t].reshape(-1) * np.array([e1, e2, e3, e4, e5, e6, e7, e8, e9, e10, e11, e12, e13, e14, e15, e16]).dot(layers.reshape((16, -1))),\n",
    "                xdata = t,\n",
    "                ydata = rho[p, ..., t].reshape(-1),\n",
    "                p0    = epsilon.loc[p, t-1]\n",
    "            )[0]\n",
    "\n",
    "def fit_r0_m(fn):\n",
    "    ts = np.tile(points, n_rows * n_columns)\n",
    "    \n",
    "    for p in plates:\n",
    "        ci = alphas.loc[p, \"c i\"].values.repeat(207)\n",
    "        \n",
    "        r0_m.loc[p] = curve_fit(\n",
    "            f     = lambda _, r0, m:\n",
    "                r0 * ci / (ci + np.exp(-m * ts)) * fn(p),\n",
    "            xdata = 80085,\n",
    "            ydata = rho[p].reshape(-1)\n",
    "        )[0]\n",
    "\n",
    "def fit_ci(fn):\n",
    "    for p in plates:\n",
    "        r0, m = r0_m.loc[p]\n",
    "        \n",
    "        for r, c in product(rows, columns):\n",
    "            c_i[p, r, c] = curve_fit(\n",
    "                f      = lambda _, ci:\n",
    "                    r0 * ci / (ci + np.exp(-m * points)) * fn(p, r, c),\n",
    "                xdata  = 80085,\n",
    "                ydata  = rho[p, r, c],\n",
    "                bounds = (0, np.inf)\n",
    "            )[0]\n",
    "\n",
    "def update_alpha():\n",
    "    global previous_alphas, previous_alpha\n",
    "    \n",
    "    previous_alphas = alphas.copy()\n",
    "    alphas.loc[:, \"r0 i\"] = list(r0_m[\"r0\"].repeat(n_rows * n_columns))\n",
    "    alphas.loc[:, \"m i\"] = list(r0_m[\"m\"].repeat(n_rows * n_columns))\n",
    "    alphas.loc[:, \"c i\"] = list(c_i)\n",
    "    \n",
    "    previous_alpha = alpha.copy()\n",
    "    for idx in product(plates, rows, columns):\n",
    "        r0, ci, mi = alphas.loc[idx]\n",
    "        alpha[idx] = r0 * ci / (ci + np.exp(-mi * points))\n",
    "\n",
    "def refit_alphas(r0m_fn, ci_fn):\n",
    "    fit_r0_m(r0m_fn)\n",
    "    fit_ci(ci_fn)\n",
    "    update_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fbe1acb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n"
     ]
    }
   ],
   "source": [
    "previous_score = np.inf\n",
    "for it in range(n_iterations):\n",
    "    print(f\"iteration {it+1}\")\n",
    "    \n",
    "    fit_new_epsilons()\n",
    "    refit_alphas(\n",
    "        r0m_fn = lambda p: epsilon.loc[p].dot(layers.reshape((16, -1))).T.values.reshape(-1),\n",
    "        ci_fn = lambda p, r, c: epsilon.loc[p, f\"epsilon {c2l[r, c]}\"]\n",
    "    )\n",
    "    \n",
    "    predictions = np.array([\n",
    "            alpha[p].reshape((-1, n_points))\n",
    "        *   epsilon.loc[p].dot(layers.reshape((16, -1))).T.values\n",
    "        for p in plates\n",
    "    ]).reshape((n_plates, n_rows, n_columns, n_points))\n",
    "        \n",
    "    current_score = lse(predictions.reshape(-1), rho.reshape(-1))\n",
    "    \n",
    "    if current_score < previous_score:\n",
    "        previous_score = current_score\n",
    "    else:\n",
    "        alphas = previous_alphas\n",
    "        alpha = previous_alpha\n",
    "        epsilon = previous_epsilon\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f397a67e",
   "metadata": {},
   "source": [
    "We save the obtained $\\alpha_i(t)$ and $\\epsilon_k(t)$ for re-use with the $\\hat\\rho_i(t) = \\alpha_i(t) \\; \\epsilon_k(t) \\; \\phi(N_i(t))$ model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ba700fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas.to_csv(\"alpha/params_alpha-epsilon_k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1c1f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"alpha/alpha-epsilon_k.npy\", alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69c9c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon.to_csv(\"epsilon/alpha-epsilon_k.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12055f84",
   "metadata": {},
   "source": [
    "And the predictions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07c84671",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([\n",
    "        alpha[p].reshape((-1, n_points))\n",
    "    *   epsilon.loc[p].dot(layers.reshape((16, -1))).T.values\n",
    "    for p in plates\n",
    "]).reshape((n_plates, n_rows, n_columns, n_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea5334f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"predictions/level-2_alpha-epsilon_k.npy\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
